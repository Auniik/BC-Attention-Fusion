üöÄ RUNPOD SETUP FOR BREAST CANCER CLASSIFICATION
============================================================
üîç CHECKING ENVIRONMENT
==================================================
üìä Environment: runpod
üìÇ Base path: /workspace
üéØ Dataset path: /workspace/breakhis
üìÑ Folds file: /workspace/breakhis/Folds_fixed.csv

üîç CHECKING DATASET AVAILABILITY
==================================================
‚úÖ Dataset found at: /workspace/breakhis
‚úÖ Original folds: /workspace/breakhis/Folds.csv
‚úÖ Images directory: /workspace/breakhis/BreaKHis_v1

üîç CHECKING CROSS-VALIDATION FIX
==================================================
‚ùå Fixed folds file not found: /workspace/breakhis/Folds_fixed.csv

üîß Cross-validation fix needed, applying now...

üîß APPLYING CROSS-VALIDATION FIX
==================================================
‚úÖ Cross-validation fix applied successfully!
üìÑ Output:
üîß Environment detected: runpod
üìÇ Base path: /workspace
üìÑ Input: /workspace/breakhis/Folds.csv
üìÑ Output: /workspace/breakhis/Folds_fixed.csv
Original data shape: (39545, 4)

Total unique patients: 82
Class distribution:
tumor_class
malignant    58
benign       24
Name: count, dtype: int64

Tumor type distribution:
tumor_type
ductal_carcinoma       38
fibroadenoma           10
mucinous_carcinoma      9
tubular_adenoma         7
papillary_carcinoma     6
lobular_carcinoma       5
adenosis                4
phyllodes_tumor         3
Name: count, dtype: int64

Patients per fold:
Fold 1: 17 patients
  - Benign: 5
  - Malignant: 12
Fold 2: 17 patients
  - Benign: 5
  - Malignant: 12
Fold 3: 16 patients
  - Benign: 5
  - Malignant: 11
Fold 4: 16 patients
  - Benign: 5
  - Malignant: 11
Fold 5: 16 patients
  - Benign: 4
  - Malignant: 12

=== VERIFICATION ===
Fold 1:
  Train: 65 patients, 30885 samples
  Test: 17 patients, 8660 samples
  Patient overlap: 0 (should be 0)
Fold 2:
  Train: 65 patients, 32420 samples
  Test: 17 patients, 7125 samples
  Patient overlap: 0 (should be 0)
Fold 3:
  Train: 66 patients, 30735 samples
  Test: 16 patients, 8810 samples
  Patient overlap: 0 (should be 0)
Fold 4:
  Train: 66 patients, 31600 samples
  Test: 16 patients, 7945 samples
  Patient overlap: 0 (should be 0)
Fold 5:
  Train: 66 patients, 32540 samples
  Test: 16 patients, 7005 samples
  Patient overlap: 0 (should be 0)

‚úÖ Fixed cross-validation folds saved to: /workspace/breakhis/Folds_fixed.csv
Original shape: (39545, 7), Fixed shape: (197725, 4)

üéØ Cross-validation data leakage has been FIXED!
üìä Environment: runpod
üìÑ Fixed folds saved to: /workspace/breakhis/Folds_fixed.csv
‚úÖ Ready for training with proper cross-validation!


üß™ VALIDATING CROSS-VALIDATION FIX
==================================================
‚úÖ Cross-validation fix validation PASSED!

üéâ RUNPOD SETUP COMPLETED SUCCESSFULLY!
============================================================
üìä Environment: runpod
‚úÖ Dataset: Available and verified
‚úÖ Cross-validation: Fixed and validated
üöÄ Ready to run: python main.py
üéØ Expected results: Realistic 90-96% ensemble accuracy (not 100%)

‚úÖ Setup successful. You can now run the training!
root@67a1fc13efd9:/workspace/BC-Attention-Fusion# python main.py
Dataset Statistics:
--------------------------------------------------------------------------------
Category                                 Images     Patients
--------------------------------------------------------------------------------
benign_adenosis_100X                     113        4
benign_adenosis_200X                     111        4
benign_adenosis_400X                     106        4
benign_adenosis_40X                      114        4
benign_fibroadenoma_100X                 260        10
benign_fibroadenoma_200X                 264        10
benign_fibroadenoma_400X                 237        10
benign_fibroadenoma_40X                  253        10
benign_phyllodes_tumor_100X              121        3
benign_phyllodes_tumor_200X              108        3
benign_phyllodes_tumor_400X              115        3
benign_phyllodes_tumor_40X               109        3
benign_tubular_adenoma_100X              150        7
benign_tubular_adenoma_200X              140        7
benign_tubular_adenoma_400X              130        7
benign_tubular_adenoma_40X               149        7
malignant_ductal_carcinoma_100X          903        38
malignant_ductal_carcinoma_200X          896        38
malignant_ductal_carcinoma_400X          788        38
malignant_ductal_carcinoma_40X           864        38
malignant_lobular_carcinoma_100X         170        5
malignant_lobular_carcinoma_200X         163        5
malignant_lobular_carcinoma_400X         137        5
malignant_lobular_carcinoma_40X          156        5
malignant_mucinous_carcinoma_100X        222        9
malignant_mucinous_carcinoma_200X        196        9
malignant_mucinous_carcinoma_400X        169        9
malignant_mucinous_carcinoma_40X         205        9
malignant_papillary_carcinoma_100X       142        6
malignant_papillary_carcinoma_200X       135        6
malignant_papillary_carcinoma_400X       138        6
malignant_papillary_carcinoma_40X        145        6

Folds.csv Info:
Shape: (197725, 4)

Columns: ['fold', 'mag', 'grp', 'filename']

First few rows:
   fold  mag    grp                                           filename
0     1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...
1     1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...
2     1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...
3     1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...
4     1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...

Fold distribution:
fold
1    39545
2    39545
3    39545
4    39545
5    39545
Name: count, dtype: int64

Magnification distribution:
mag
100    52025
200    50325
40     49875
400    45500
Name: count, dtype: int64

Train/Test distribution:
grp
train    158180
test      39545
Name: count, dtype: int64
        fold  mag    grp                                           filename
0          1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...
1          1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...
2          1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...
3          1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...
4          1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...
...      ...  ...    ...                                                ...
197720     5  400  train  BreaKHis_v1/histology_slides/breast/malignant/...
197721     5  400  train  BreaKHis_v1/histology_slides/breast/malignant/...
197722     5  400  train  BreaKHis_v1/histology_slides/breast/malignant/...
197723     5  400  train  BreaKHis_v1/histology_slides/breast/malignant/...
197724     5  400  train  BreaKHis_v1/histology_slides/breast/malignant/...

[197725 rows x 4 columns]
Dataset structure analysis:
Unique patients: 82

Tumor types distribution:
tumor_class  tumor_type
benign       adenosis               11100
             fibroadenoma           25350
             phyllodes_tumor        11325
             tubular_adenoma        14225
malignant    ductal_carcinoma       86275
             lobular_carcinoma      15650
             mucinous_carcinoma     19800
             papillary_carcinoma    14000
dtype: int64

Patients by number of magnifications available:
magnification
4    82
Name: count, dtype: int64

Images per patient-magnification (sample):
patient_id          magnification
SOB_B_A_14-22549AB  40               725
                    100              750
                    200              800
                    400              750
SOB_B_A_14-22549CD  40               875
                    100              900
                    200              775
                    400              750
SOB_B_A_14-22549G   40               875
                    100              850
                    200              800
                    400              725
SOB_B_A_14-29960CD  40               375
                    100              325
                    200              400
                    400              425
SOB_B_F_14-14134    40               900
                    100              775
                    200              950
                    400              925
dtype: int64

============================================================
FOLD 1 ANALYSIS
============================================================
=== CLASS DISTRIBUTION ANALYSIS ===

Class distribution by split:
tumor_class  benign  malignant
grp
test           3400       5260
train          9000      21885

Class ratio (benign:malignant) in train: 9000:21885

=== TUMOR TYPE DISTRIBUTION ===
tumor_class  tumor_type
benign       adenosis                1570
             fibroadenoma            3495
             phyllodes_tumor         1090
             tubular_adenoma         2845
malignant    ductal_carcinoma       14375
             lobular_carcinoma       1990
             mucinous_carcinoma      3045
             papillary_carcinoma     2475
dtype: int64

=== PATIENT-LEVEL ANALYSIS ===
Unique patients - Benign: 24, Malignant: 58

Images per patient stats:
Mean: 475.2, Std: 179.0

=== MAGNIFICATION BALANCE ===
mag           40    100   200   400
tumor_class
benign       2290  2295  2275  2140
malignant    5580  5750  5630  4925

=== CALCULATED WEIGHTS ===
Class weights: {'malignant': 0.705620287868403, 'benign': 1.7158333333333333}

Tumor type weights (top 5):
  phyllodes_tumor: 3.542
  adenosis: 2.459
  lobular_carcinoma: 1.940
  papillary_carcinoma: 1.560
  tubular_adenoma: 1.357
üîß Environment detected: runpod
üéØ Device: cuda
üöÄ CUDA available with 1 GPU(s)
‚ö° Tensor core optimization enabled for NVIDIA RTX 4000 Ada Generation
üìä Batch size: 16 | Workers: 8
model.safetensors: 100%|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------‚ñà‚ñà| 36.8M/36.8M [00:00<00:00, 49.7MB/s]
==== Fold 1 ====
Balanced dataset: 736 benign, 736 malignant
Dataset initialized:
  Mode: train
  Patients: 82
  Samples per epoch: 1472
  Magnifications: [40, 100, 200, 400]
Dataset initialized:
  Mode: test
  Patients: 82
  Samples per epoch: 136
  Magnifications: [40, 100, 200, 400]
üìà Using batch size: 16 | Workers: 8 | Environment: runpod
Starting training...
Starting 25 epoch training with warmup for 3 epochs
Early stopping patience: 8 epochs

Epoch 1/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:59<00:00,  1.53it/s, loss=0.5761]
Validating: 100%|----------------| 9/9 [00:37<00:00,  4.16s/it]
Train - Loss: 0.6544, Acc: 0.5000, F1: 0.4988, Bal_Acc: 0.5000
Val - Loss: 0.9037, Acc: 0.5147, F1: 0.5069, Bal_Acc: 0.4010
Per-class Acc: (B: 0.1250, M: 0.6771)
Tumor Acc: 0.2132, LR: 0.00e+00
No improvement - Per-class requirement not met (min: 0.1250 < 0.85)

Epoch 2/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.14it/s, loss=0.2300]
Validating: 100%|----------------| 9/9 [00:01<00:00,  4.95it/s]
Train - Loss: 0.3818, Acc: 0.8302, F1: 0.8300, Bal_Acc: 0.8302
Val - Loss: 0.6584, Acc: 0.8971, F1: 0.8995, Bal_Acc: 0.9052
Per-class Acc: (B: 0.9250, M: 0.8854)
Tumor Acc: 0.5809, LR: 1.67e-04
üéØ New best accuracy: 0.8971 (Bal: 0.9052) - Model saved!
   Per-class performance: B=0.9250, M=0.8854 ‚úÖ

Epoch 3/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.14it/s, loss=0.2353]
Validating: 100%|----------------| 9/9 [00:01<00:00,  4.81it/s]
Train - Loss: 0.2164, Acc: 0.9477, F1: 0.9477, Bal_Acc: 0.9477
Val - Loss: 0.5826, Acc: 0.9191, F1: 0.9188, Bal_Acc: 0.8990
Per-class Acc: (B: 0.8500, M: 0.9479)
Tumor Acc: 0.5588, LR: 3.33e-04
üéØ New best accuracy: 0.9191 (Bal: 0.8990) - Model saved!
   Per-class performance: B=0.8500, M=0.9479 ‚úÖ

Epoch 4/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.11it/s, loss=0.2151]
Validating: 100%|----------------| 9/9 [00:01<00:00,  5.05it/s]
Train - Loss: 0.1885, Acc: 0.9436, F1: 0.9436, Bal_Acc: 0.9436
Val - Loss: 0.6448, Acc: 0.8897, F1: 0.8915, Bal_Acc: 0.8854
Per-class Acc: (B: 0.8750, M: 0.8958)
Tumor Acc: 0.5515, LR: 5.00e-04
No improvement for 1/8 epochs

Epoch 5/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.12it/s, loss=0.1227]
Validating: 100%|----------------| 9/9 [00:01<00:00,  5.11it/s]
Train - Loss: 0.1792, Acc: 0.9531, F1: 0.9531, Bal_Acc: 0.9531
Val - Loss: 0.5984, Acc: 0.8824, F1: 0.8739, Bal_Acc: 0.8073
Per-class Acc: (B: 0.6250, M: 0.9896)
Tumor Acc: 0.5588, LR: 4.97e-04
No improvement - Per-class requirement not met (min: 0.6250 < 0.85)

Epoch 6/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:21<00:00,  4.20it/s, loss=0.1066]
Validating: 100%|----------------| 9/9 [00:01<00:00,  5.20it/s]
Train - Loss: 0.1313, Acc: 0.9688, F1: 0.9687, Bal_Acc: 0.9688
Val - Loss: 0.6185, Acc: 0.8750, F1: 0.8763, Bal_Acc: 0.8604
Per-class Acc: (B: 0.8250, M: 0.8958)
Tumor Acc: 0.5809, LR: 4.90e-04
No improvement - Per-class requirement not met (min: 0.8250 < 0.85)

Epoch 7/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.13it/s, loss=0.1056]
Validating: 100%|----------------| 9/9 [00:01<00:00,  5.31it/s]
Train - Loss: 0.1329, Acc: 0.9640, F1: 0.9640, Bal_Acc: 0.9640
Val - Loss: 0.5986, Acc: 0.9191, F1: 0.9199, Bal_Acc: 0.9135
Per-class Acc: (B: 0.9000, M: 0.9271)
Tumor Acc: 0.6324, LR: 4.77e-04
No improvement for 4/8 epochs

Epoch 8/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.11it/s, loss=0.0833]
Validating: 100%|----------------| 9/9 [00:01<00:00,  5.34it/s]
Train - Loss: 0.1049, Acc: 0.9823, F1: 0.9823, Bal_Acc: 0.9823
Val - Loss: 0.5771, Acc: 0.8824, F1: 0.8794, Bal_Acc: 0.8365
Per-class Acc: (B: 0.7250, M: 0.9479)
Tumor Acc: 0.5956, LR: 4.60e-04
No improvement - Per-class requirement not met (min: 0.7250 < 0.85)

Epoch 9/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.13it/s, loss=0.1345]
Validating: 100%|----------------| 9/9 [00:01<00:00,  5.24it/s]
Train - Loss: 0.1112, Acc: 0.9810, F1: 0.9810, Bal_Acc: 0.9810
Val - Loss: 0.6851, Acc: 0.8603, F1: 0.8608, Bal_Acc: 0.8354
Per-class Acc: (B: 0.7750, M: 0.8958)
Tumor Acc: 0.5588, LR: 4.39e-04
No improvement - Per-class requirement not met (min: 0.7750 < 0.85)

Epoch 10/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.15it/s, loss=0.0999]
Validating: 100%|----------------| 9/9 [00:01<00:00,  5.33it/s]
Train - Loss: 0.1166, Acc: 0.9674, F1: 0.9674, Bal_Acc: 0.9674
Val - Loss: 0.5468, Acc: 0.9265, F1: 0.9239, Bal_Acc: 0.8823
Per-class Acc: (B: 0.7750, M: 0.9896)
Tumor Acc: 0.6618, LR: 4.14e-04
No improvement - Per-class requirement not met (min: 0.7750 < 0.85)

Epoch 11/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.14it/s, loss=0.0811]
Validating: 100%|----------------| 9/9 [00:01<00:00,  5.12it/s]
Train - Loss: 0.0794, Acc: 0.9891, F1: 0.9891, Bal_Acc: 0.9891
Val - Loss: 0.6606, Acc: 0.9044, F1: 0.9048, Bal_Acc: 0.8885
Per-class Acc: (B: 0.8500, M: 0.9271)
Tumor Acc: 0.5809, LR: 3.85e-04
No improvement for 8/8 epochs

‚èπÔ∏è Early stopping triggered after 11 epochs
Best standard accuracy: 0.9191
Best balanced accuracy: 0.8990

üìä Loading best checkpoint for final evaluation...
/workspace/BC-Attention-Fusion/main.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(f'output/best_model_fold_{fold}.pth', map_location=device)
üîç Re-evaluating with best checkpoint...

=== DETAILED CLASSIFICATION REPORT ===
              precision    recall  f1-score   support

      benign     0.8571    0.7500    0.8000        40
   malignant     0.9010    0.9479    0.9239        96

    accuracy                         0.8897       136
   macro avg     0.8791    0.8490    0.8619       136
weighted avg     0.8881    0.8897    0.8874       136


=== CONFUSION MATRIX ===
Predicted:  benign  malignant
benign:         30       10
malignant:       5       91

=== KEY INSIGHTS ===
Benign Recall: 0.7500 (30/40)
Malignant Recall: 0.9479 (91/96)

Prediction distribution: benign=35, malignant=101
Analyzing cross-magnification feature importance...

Final Validation Accuracy: 0.9044

Magnification Importance Analysis:
40x contribution: 0.0375 ¬± 0.0702
100x contribution: 0.0314 ¬± 0.0585
200x contribution: 0.0256 ¬± 0.0768
400x contribution: 0.0311 ¬± 0.0703
==== Fold 2 ====
Balanced dataset: 736 benign, 736 malignant
Dataset initialized:
  Mode: train
  Patients: 82
  Samples per epoch: 1472
  Magnifications: [40, 100, 200, 400]
Dataset initialized:
  Mode: test
  Patients: 82
  Samples per epoch: 136
  Magnifications: [40, 100, 200, 400]
üìà Using batch size: 16 | Workers: 8 | Environment: runpod
Starting training...
Starting 25 epoch training with warmup for 3 epochs
Early stopping patience: 8 epochs

Epoch 1/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:57<00:00,  1.59it/s, loss=0.3078]
Validating: 100%|----------------| 9/9 [00:37<00:00,  4.15s/it]
Train - Loss: 0.2684, Acc: 0.9198, F1: 0.9198, Bal_Acc: 0.9198
Val - Loss: 0.3830, Acc: 0.9926, F1: 0.9926, Bal_Acc: 0.9875
Per-class Acc: (B: 0.9750, M: 1.0000)
Tumor Acc: 0.6985, LR: 0.00e+00
üéØ New best accuracy: 0.9926 (Bal: 0.9875) - Model saved!
   Per-class performance: B=0.9750, M=1.0000 ‚úÖ

Epoch 2/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.12it/s, loss=0.1724]
Validating: 100%|----------------| 9/9 [00:01<00:00,  4.51it/s]
Train - Loss: 0.2122, Acc: 0.9375, F1: 0.9375, Bal_Acc: 0.9375
Val - Loss: 0.4418, Acc: 0.9632, F1: 0.9638, Bal_Acc: 0.9740
Per-class Acc: (B: 1.0000, M: 0.9479)
Tumor Acc: 0.6985, LR: 1.67e-04
No improvement for 1/8 epochs

Epoch 3/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.12it/s, loss=0.1268]
Validating: 100%|----------------| 9/9 [00:01<00:00,  4.91it/s]
Train - Loss: 0.2062, Acc: 0.9368, F1: 0.9368, Bal_Acc: 0.9368
Val - Loss: 0.4539, Acc: 0.9191, F1: 0.9167, Bal_Acc: 0.8771
Per-class Acc: (B: 0.7750, M: 0.9792)
Tumor Acc: 0.6618, LR: 3.33e-04
No improvement - Per-class requirement not met (min: 0.7750 < 0.85)

Epoch 4/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.11it/s, loss=0.3216]
Validating: 100%|----------------| 9/9 [00:01<00:00,  4.95it/s]
Train - Loss: 0.2260, Acc: 0.9266, F1: 0.9266, Bal_Acc: 0.9266
Val - Loss: 0.4784, Acc: 0.9559, F1: 0.9552, Bal_Acc: 0.9323
Per-class Acc: (B: 0.8750, M: 0.9896)
Tumor Acc: 0.6103, LR: 5.00e-04
No improvement for 3/8 epochs

Epoch 5/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.17it/s, loss=0.1515]
Validating: 100%|----------------| 9/9 [00:01<00:00,  4.51it/s]
Train - Loss: 0.2203, Acc: 0.9341, F1: 0.9341, Bal_Acc: 0.9341
Val - Loss: 0.4157, Acc: 0.9779, F1: 0.9782, Bal_Acc: 0.9844
Per-class Acc: (B: 1.0000, M: 0.9688)
Tumor Acc: 0.6838, LR: 4.97e-04
No improvement for 4/8 epochs

Epoch 6/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.12it/s, loss=0.2149]
Validating: 100%|----------------| 9/9 [00:01<00:00,  4.97it/s]
Train - Loss: 0.2174, Acc: 0.9253, F1: 0.9253, Bal_Acc: 0.9253
Val - Loss: 0.4510, Acc: 0.9853, F1: 0.9852, Bal_Acc: 0.9750
Per-class Acc: (B: 0.9500, M: 1.0000)
Tumor Acc: 0.6103, LR: 4.90e-04
No improvement for 5/8 epochs

Epoch 7/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.12it/s, loss=0.1119]
Validating: 100%|----------------| 9/9 [00:01<00:00,  4.97it/s]
Train - Loss: 0.1944, Acc: 0.9402, F1: 0.9402, Bal_Acc: 0.9402
Val - Loss: 0.4009, Acc: 0.9926, F1: 0.9926, Bal_Acc: 0.9875
Per-class Acc: (B: 0.9750, M: 1.0000)
Tumor Acc: 0.6324, LR: 4.77e-04
No improvement for 6/8 epochs

Epoch 8/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.10it/s, loss=0.1616]
Validating: 100%|----------------| 9/9 [00:01<00:00,  5.09it/s]
Train - Loss: 0.1745, Acc: 0.9538, F1: 0.9538, Bal_Acc: 0.9538
Val - Loss: 0.4570, Acc: 0.9559, F1: 0.9548, Bal_Acc: 0.9250
Per-class Acc: (B: 0.8500, M: 1.0000)
Tumor Acc: 0.6397, LR: 4.60e-04
No improvement for 7/8 epochs

Epoch 9/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.16it/s, loss=0.1041]
Validating: 100%|----------------| 9/9 [00:01<00:00,  5.01it/s]
Train - Loss: 0.1586, Acc: 0.9572, F1: 0.9572, Bal_Acc: 0.9572
Val - Loss: 0.3934, Acc: 0.9853, F1: 0.9853, Bal_Acc: 0.9823
Per-class Acc: (B: 0.9750, M: 0.9896)
Tumor Acc: 0.6471, LR: 4.39e-04
No improvement for 8/8 epochs

‚èπÔ∏è Early stopping triggered after 9 epochs
Best standard accuracy: 0.9926
Best balanced accuracy: 0.9875

üìä Loading best checkpoint for final evaluation...
/workspace/BC-Attention-Fusion/main.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(f'output/best_model_fold_{fold}.pth', map_location=device)
üîç Re-evaluating with best checkpoint...

=== DETAILED CLASSIFICATION REPORT ===
              precision    recall  f1-score   support

      benign     1.0000    0.9750    0.9873        40
   malignant     0.9897    1.0000    0.9948        96

    accuracy                         0.9926       136
   macro avg     0.9948    0.9875    0.9911       136
weighted avg     0.9927    0.9926    0.9926       136


=== CONFUSION MATRIX ===
Predicted:  benign  malignant
benign:         39        1
malignant:       0       96

=== KEY INSIGHTS ===
Benign Recall: 0.9750 (39/40)
Malignant Recall: 1.0000 (96/96)

Prediction distribution: benign=39, malignant=97
Analyzing cross-magnification feature importance...

Final Validation Accuracy: 1.0000

Magnification Importance Analysis:
40x contribution: 0.0421 ¬± 0.0412
100x contribution: 0.0557 ¬± 0.0721
200x contribution: 0.0508 ¬± 0.0691
400x contribution: 0.0276 ¬± 0.0416
==== Fold 3 ====
Balanced dataset: 752 benign, 752 malignant
Dataset initialized:
  Mode: train
  Patients: 82
  Samples per epoch: 1504
  Magnifications: [40, 100, 200, 400]
Dataset initialized:
  Mode: test
  Patients: 82
  Samples per epoch: 128
  Magnifications: [40, 100, 200, 400]
üìà Using batch size: 16 | Workers: 8 | Environment: runpod
Starting training...
Starting 25 epoch training with warmup for 3 epochs
Early stopping patience: 8 epochs

Epoch 1/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:57<00:00,  1.62it/s, loss=0.3152]
Validating: 100%|----------------| 8/8 [00:36<00:00,  4.58s/it]
Train - Loss: 0.2665, Acc: 0.9122, F1: 0.9122, Bal_Acc: 0.9122
Val - Loss: 0.3788, Acc: 1.0000, F1: 1.0000, Bal_Acc: 1.0000
Per-class Acc: (B: 1.0000, M: 1.0000)
Tumor Acc: 0.7578, LR: 0.00e+00
üéØ New best accuracy: 1.0000 (Bal: 1.0000) - Model saved!
   Per-class performance: B=1.0000, M=1.0000 ‚úÖ

Epoch 2/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.17it/s, loss=0.2124]
Validating: 100%|----------------| 8/8 [00:01<00:00,  4.87it/s]
Train - Loss: 0.2216, Acc: 0.9335, F1: 0.9335, Bal_Acc: 0.9335
Val - Loss: 0.4604, Acc: 0.9297, F1: 0.9277, Bal_Acc: 0.8943
Per-class Acc: (B: 0.8000, M: 0.9886)
Tumor Acc: 0.7500, LR: 1.67e-04
No improvement - Per-class requirement not met (min: 0.8000 < 0.85)

Epoch 3/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.13it/s, loss=0.1695]
Validating: 100%|----------------| 8/8 [00:01<00:00,  4.65it/s]
Train - Loss: 0.1923, Acc: 0.9461, F1: 0.9461, Bal_Acc: 0.9461
Val - Loss: 0.5988, Acc: 0.8281, F1: 0.8205, Bal_Acc: 0.7659
Per-class Acc: (B: 0.6000, M: 0.9318)
Tumor Acc: 0.5391, LR: 3.33e-04
No improvement - Per-class requirement not met (min: 0.6000 < 0.85)

Epoch 4/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.13it/s, loss=0.1534]
Validating: 100%|----------------| 8/8 [00:01<00:00,  4.93it/s]
Train - Loss: 0.2000, Acc: 0.9355, F1: 0.9355, Bal_Acc: 0.9355
Val - Loss: 0.6151, Acc: 0.8516, F1: 0.8487, Bal_Acc: 0.8102
Per-class Acc: (B: 0.7000, M: 0.9205)
Tumor Acc: 0.4844, LR: 5.00e-04
No improvement - Per-class requirement not met (min: 0.7000 < 0.85)

Epoch 5/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.12it/s, loss=0.3917]
Validating: 100%|----------------| 8/8 [00:01<00:00,  4.85it/s]
Train - Loss: 0.2117, Acc: 0.9415, F1: 0.9415, Bal_Acc: 0.9415
Val - Loss: 0.6067, Acc: 0.9141, F1: 0.9124, Bal_Acc: 0.8830
Per-class Acc: (B: 0.8000, M: 0.9659)
Tumor Acc: 0.4453, LR: 4.97e-04
No improvement - Per-class requirement not met (min: 0.8000 < 0.85)

Epoch 6/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.17it/s, loss=0.1184]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.08it/s]
Train - Loss: 0.2124, Acc: 0.9375, F1: 0.9375, Bal_Acc: 0.9375
Val - Loss: 0.6645, Acc: 0.8125, F1: 0.8062, Bal_Acc: 0.7545
Per-class Acc: (B: 0.6000, M: 0.9091)
Tumor Acc: 0.5547, LR: 4.90e-04
No improvement - Per-class requirement not met (min: 0.6000 < 0.85)

Epoch 7/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.16it/s, loss=0.2639]
Validating: 100%|----------------| 8/8 [00:01<00:00,  4.94it/s]
Train - Loss: 0.1756, Acc: 0.9548, F1: 0.9548, Bal_Acc: 0.9548
Val - Loss: 0.6698, Acc: 0.8203, F1: 0.8183, Bal_Acc: 0.7807
Per-class Acc: (B: 0.6750, M: 0.8864)
Tumor Acc: 0.4531, LR: 4.77e-04
No improvement - Per-class requirement not met (min: 0.6750 < 0.85)

Epoch 8/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.16it/s, loss=0.1069]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.04it/s]
Train - Loss: 0.1498, Acc: 0.9641, F1: 0.9641, Bal_Acc: 0.9641
Val - Loss: 0.7328, Acc: 0.8281, F1: 0.8240, Bal_Acc: 0.7795
Per-class Acc: (B: 0.6500, M: 0.9091)
Tumor Acc: 0.4609, LR: 4.60e-04
No improvement - Per-class requirement not met (min: 0.6500 < 0.85)

Epoch 9/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.17it/s, loss=0.2152]
Validating: 100%|----------------| 8/8 [00:01<00:00,  4.93it/s]
Train - Loss: 0.1335, Acc: 0.9721, F1: 0.9721, Bal_Acc: 0.9721
Val - Loss: 0.9277, Acc: 0.8828, F1: 0.8815, Bal_Acc: 0.8534
Per-class Acc: (B: 0.7750, M: 0.9318)
Tumor Acc: 0.4688, LR: 4.39e-04
No improvement - Per-class requirement not met (min: 0.7750 < 0.85)

‚èπÔ∏è Early stopping triggered after 9 epochs
Best standard accuracy: 1.0000
Best balanced accuracy: 1.0000

üìä Loading best checkpoint for final evaluation...
/workspace/BC-Attention-Fusion/main.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(f'output/best_model_fold_{fold}.pth', map_location=device)
üîç Re-evaluating with best checkpoint...

=== DETAILED CLASSIFICATION REPORT ===
              precision    recall  f1-score   support

      benign     1.0000    0.9750    0.9873        40
   malignant     0.9888    1.0000    0.9944        88

    accuracy                         0.9922       128
   macro avg     0.9944    0.9875    0.9908       128
weighted avg     0.9923    0.9922    0.9922       128


=== CONFUSION MATRIX ===
Predicted:  benign  malignant
benign:         39        1
malignant:       0       88

=== KEY INSIGHTS ===
Benign Recall: 0.9750 (39/40)
Malignant Recall: 1.0000 (88/88)

Prediction distribution: benign=39, malignant=89
Analyzing cross-magnification feature importance...

Final Validation Accuracy: 0.9922

Magnification Importance Analysis:
40x contribution: 0.0608 ¬± 0.0631
100x contribution: 0.0358 ¬± 0.0569
200x contribution: 0.0346 ¬± 0.0698
400x contribution: 0.0393 ¬± 0.0489
==== Fold 4 ====
Balanced dataset: 752 benign, 752 malignant
Dataset initialized:
  Mode: train
  Patients: 82
  Samples per epoch: 1504
  Magnifications: [40, 100, 200, 400]
Dataset initialized:
  Mode: test
  Patients: 82
  Samples per epoch: 128
  Magnifications: [40, 100, 200, 400]
üìà Using batch size: 16 | Workers: 8 | Environment: runpod
Starting training...
Starting 25 epoch training with warmup for 3 epochs
Early stopping patience: 8 epochs

Epoch 1/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:58<00:00,  1.61it/s, loss=0.1627]
Validating: 100%|----------------| 8/8 [00:36<00:00,  4.58s/it]
Train - Loss: 0.2408, Acc: 0.9209, F1: 0.9209, Bal_Acc: 0.9209
Val - Loss: 0.4037, Acc: 1.0000, F1: 1.0000, Bal_Acc: 1.0000
Per-class Acc: (B: 1.0000, M: 1.0000)
Tumor Acc: 0.6797, LR: 0.00e+00
üéØ New best accuracy: 1.0000 (Bal: 1.0000) - Model saved!
   Per-class performance: B=1.0000, M=1.0000 ‚úÖ

Epoch 2/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.16it/s, loss=0.2698]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.08it/s]
Train - Loss: 0.1852, Acc: 0.9521, F1: 0.9521, Bal_Acc: 0.9521
Val - Loss: 0.5392, Acc: 0.8984, F1: 0.8994, Bal_Acc: 0.8920
Per-class Acc: (B: 0.8750, M: 0.9091)
Tumor Acc: 0.5234, LR: 1.67e-04
No improvement for 1/8 epochs

Epoch 3/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.15it/s, loss=0.1171]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.15it/s]
Train - Loss: 0.2078, Acc: 0.9295, F1: 0.9295, Bal_Acc: 0.9295
Val - Loss: 0.5848, Acc: 0.9062, F1: 0.9040, Bal_Acc: 0.8705
Per-class Acc: (B: 0.7750, M: 0.9659)
Tumor Acc: 0.5469, LR: 3.33e-04
No improvement - Per-class requirement not met (min: 0.7750 < 0.85)

Epoch 4/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.13it/s, loss=0.1538]
Validating: 100%|----------------| 8/8 [00:01<00:00,  4.82it/s]
Train - Loss: 0.2087, Acc: 0.9289, F1: 0.9289, Bal_Acc: 0.9289
Val - Loss: 0.6069, Acc: 0.8984, F1: 0.8981, Bal_Acc: 0.8784
Per-class Acc: (B: 0.8250, M: 0.9318)
Tumor Acc: 0.3906, LR: 5.00e-04
No improvement - Per-class requirement not met (min: 0.8250 < 0.85)

Epoch 5/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:23<00:00,  4.07it/s, loss=0.1616]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.12it/s]
Train - Loss: 0.1971, Acc: 0.9455, F1: 0.9455, Bal_Acc: 0.9455
Val - Loss: 0.6790, Acc: 0.8906, F1: 0.8880, Bal_Acc: 0.8523
Per-class Acc: (B: 0.7500, M: 0.9545)
Tumor Acc: 0.3203, LR: 4.97e-04
No improvement - Per-class requirement not met (min: 0.7500 < 0.85)

Epoch 6/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:23<00:00,  4.04it/s, loss=0.1962]
Validating: 100%|----------------| 8/8 [00:01<00:00,  4.87it/s]
Train - Loss: 0.2376, Acc: 0.9215, F1: 0.9215, Bal_Acc: 0.9215
Val - Loss: 0.6182, Acc: 0.8906, F1: 0.8890, Bal_Acc: 0.8591
Per-class Acc: (B: 0.7750, M: 0.9432)
Tumor Acc: 0.4453, LR: 4.90e-04
No improvement - Per-class requirement not met (min: 0.7750 < 0.85)

Epoch 7/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.11it/s, loss=0.0842]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.29it/s]
Train - Loss: 0.1912, Acc: 0.9521, F1: 0.9521, Bal_Acc: 0.9521
Val - Loss: 0.5789, Acc: 0.9297, F1: 0.9269, Bal_Acc: 0.8875
Per-class Acc: (B: 0.7750, M: 1.0000)
Tumor Acc: 0.4141, LR: 4.77e-04
No improvement - Per-class requirement not met (min: 0.7750 < 0.85)

Epoch 8/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.09it/s, loss=0.4990]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.26it/s]
Train - Loss: 0.1784, Acc: 0.9528, F1: 0.9528, Bal_Acc: 0.9528
Val - Loss: 0.7062, Acc: 0.8906, F1: 0.8845, Bal_Acc: 0.8318
Per-class Acc: (B: 0.6750, M: 0.9886)
Tumor Acc: 0.3438, LR: 4.60e-04
No improvement - Per-class requirement not met (min: 0.6750 < 0.85)

Epoch 9/25
--------------------------------------------------
Training: 100%|--------| 94/94 [00:22<00:00,  4.17it/s, loss=0.1499]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.26it/s]
Train - Loss: 0.1999, Acc: 0.9475, F1: 0.9475, Bal_Acc: 0.9475
Val - Loss: 0.8246, Acc: 0.9297, F1: 0.9269, Bal_Acc: 0.8875
Per-class Acc: (B: 0.7750, M: 1.0000)
Tumor Acc: 0.2969, LR: 4.39e-04
No improvement - Per-class requirement not met (min: 0.7750 < 0.85)

‚èπÔ∏è Early stopping triggered after 9 epochs
Best standard accuracy: 1.0000
Best balanced accuracy: 1.0000

üìä Loading best checkpoint for final evaluation...
/workspace/BC-Attention-Fusion/main.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(f'output/best_model_fold_{fold}.pth', map_location=device)
üîç Re-evaluating with best checkpoint...

=== DETAILED CLASSIFICATION REPORT ===
              precision    recall  f1-score   support

      benign     1.0000    0.9750    0.9873        40
   malignant     0.9888    1.0000    0.9944        88

    accuracy                         0.9922       128
   macro avg     0.9944    0.9875    0.9908       128
weighted avg     0.9923    0.9922    0.9922       128


=== CONFUSION MATRIX ===
Predicted:  benign  malignant
benign:         39        1
malignant:       0       88

=== KEY INSIGHTS ===
Benign Recall: 0.9750 (39/40)
Malignant Recall: 1.0000 (88/88)

Prediction distribution: benign=39, malignant=89
Analyzing cross-magnification feature importance...

Final Validation Accuracy: 0.9922

Magnification Importance Analysis:
40x contribution: 0.0460 ¬± 0.0432
100x contribution: 0.0543 ¬± 0.0789
200x contribution: 0.0345 ¬± 0.0598
400x contribution: 0.0354 ¬± 0.0567
==== Fold 5 ====
Balanced dataset: 736 benign, 736 malignant
Dataset initialized:
  Mode: train
  Patients: 82
  Samples per epoch: 1472
  Magnifications: [40, 100, 200, 400]
Dataset initialized:
  Mode: test
  Patients: 82
  Samples per epoch: 128
  Magnifications: [40, 100, 200, 400]
üìà Using batch size: 16 | Workers: 8 | Environment: runpod
Starting training...
Starting 25 epoch training with warmup for 3 epochs
Early stopping patience: 8 epochs

Epoch 1/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:58<00:00,  1.58it/s, loss=0.2420]
Validating: 100%|----------------| 8/8 [00:36<00:00,  4.60s/it]
Train - Loss: 0.2506, Acc: 0.9314, F1: 0.9314, Bal_Acc: 0.9314
Val - Loss: 0.3864, Acc: 0.9844, F1: 0.9845, Bal_Acc: 0.9896
Per-class Acc: (B: 1.0000, M: 0.9792)
Tumor Acc: 0.8047, LR: 0.00e+00
üéØ New best accuracy: 0.9844 (Bal: 0.9896) - Model saved!
   Per-class performance: B=1.0000, M=0.9792 ‚úÖ

Epoch 2/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.12it/s, loss=0.1132]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.38it/s]
Train - Loss: 0.2032, Acc: 0.9436, F1: 0.9436, Bal_Acc: 0.9436
Val - Loss: 0.4864, Acc: 0.9062, F1: 0.9105, Bal_Acc: 0.9375
Per-class Acc: (B: 1.0000, M: 0.8750)
Tumor Acc: 0.7422, LR: 1.67e-04
No improvement for 1/8 epochs

Epoch 3/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.12it/s, loss=0.1878]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.47it/s]
Train - Loss: 0.2094, Acc: 0.9300, F1: 0.9300, Bal_Acc: 0.9300
Val - Loss: 0.5240, Acc: 0.9297, F1: 0.9318, Bal_Acc: 0.9427
Per-class Acc: (B: 0.9688, M: 0.9167)
Tumor Acc: 0.6484, LR: 3.33e-04
No improvement for 2/8 epochs

Epoch 4/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.13it/s, loss=0.1616]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.10it/s]
Train - Loss: 0.2452, Acc: 0.9185, F1: 0.9185, Bal_Acc: 0.9185
Val - Loss: 0.5604, Acc: 0.9297, F1: 0.9318, Bal_Acc: 0.9427
Per-class Acc: (B: 0.9688, M: 0.9167)
Tumor Acc: 0.6562, LR: 5.00e-04
No improvement for 3/8 epochs

Epoch 5/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.14it/s, loss=0.1776]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.35it/s]
Train - Loss: 0.2476, Acc: 0.9212, F1: 0.9212, Bal_Acc: 0.9212
Val - Loss: 0.7274, Acc: 0.8594, F1: 0.8675, Bal_Acc: 0.9062
Per-class Acc: (B: 1.0000, M: 0.8125)
Tumor Acc: 0.6250, LR: 4.97e-04
No improvement - Per-class requirement not met (min: 0.8125 < 0.85)

Epoch 6/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.11it/s, loss=0.2206]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.26it/s]
Train - Loss: 0.2307, Acc: 0.9321, F1: 0.9321, Bal_Acc: 0.9321
Val - Loss: 0.5705, Acc: 0.8672, F1: 0.8729, Bal_Acc: 0.8802
Per-class Acc: (B: 0.9062, M: 0.8542)
Tumor Acc: 0.7188, LR: 4.90e-04
No improvement for 5/8 epochs

Epoch 7/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.14it/s, loss=0.1744]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.16it/s]
Train - Loss: 0.1967, Acc: 0.9477, F1: 0.9477, Bal_Acc: 0.9477
Val - Loss: 0.8610, Acc: 0.8281, F1: 0.8390, Bal_Acc: 0.8854
Per-class Acc: (B: 1.0000, M: 0.7708)
Tumor Acc: 0.5391, LR: 4.77e-04
No improvement - Per-class requirement not met (min: 0.7708 < 0.85)

Epoch 8/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.11it/s, loss=0.1813]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.33it/s]
Train - Loss: 0.1757, Acc: 0.9606, F1: 0.9606, Bal_Acc: 0.9606
Val - Loss: 0.7369, Acc: 0.8359, F1: 0.8457, Bal_Acc: 0.8802
Per-class Acc: (B: 0.9688, M: 0.7917)
Tumor Acc: 0.5938, LR: 4.60e-04
No improvement - Per-class requirement not met (min: 0.7917 < 0.85)

Epoch 9/25
--------------------------------------------------
Training: 100%|--------| 92/92 [00:22<00:00,  4.15it/s, loss=0.2152]
Validating: 100%|----------------| 8/8 [00:01<00:00,  5.22it/s]
Train - Loss: 0.1880, Acc: 0.9552, F1: 0.9552, Bal_Acc: 0.9552
Val - Loss: 0.5680, Acc: 0.9219, F1: 0.9245, Bal_Acc: 0.9375
Per-class Acc: (B: 0.9688, M: 0.9062)
Tumor Acc: 0.5391, LR: 4.39e-04
No improvement for 8/8 epochs

‚èπÔ∏è Early stopping triggered after 9 epochs
Best standard accuracy: 0.9844
Best balanced accuracy: 0.9896

üìä Loading best checkpoint for final evaluation...
/workspace/BC-Attention-Fusion/main.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(f'output/best_model_fold_{fold}.pth', map_location=device)
üîç Re-evaluating with best checkpoint...

=== DETAILED CLASSIFICATION REPORT ===
              precision    recall  f1-score   support

      benign     0.9697    1.0000    0.9846        32
   malignant     1.0000    0.9896    0.9948        96

    accuracy                         0.9922       128
   macro avg     0.9848    0.9948    0.9897       128
weighted avg     0.9924    0.9922    0.9922       128


=== CONFUSION MATRIX ===
Predicted:  benign  malignant
benign:         32        0
malignant:       1       95

=== KEY INSIGHTS ===
Benign Recall: 1.0000 (32/32)
Malignant Recall: 0.9896 (95/96)

Prediction distribution: benign=33, malignant=95
Analyzing cross-magnification feature importance...

Final Validation Accuracy: 1.0000

Magnification Importance Analysis:
40x contribution: 0.0382 ¬± 0.0391
100x contribution: 0.0270 ¬± 0.0513
200x contribution: 0.0345 ¬± 0.0803
400x contribution: 0.0324 ¬± 0.0450
/workspace/BC-Attention-Fusion/plotting.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 6))

üìä Cross-Fold Summary Statistics:
 fold_no  multi_mag_patients_count  single_mag_patients_count  train_samples  test_samples
       1                        82                          0          30885          8660
       2                        82                          0          32420          7125
       3                        82                          0          30735          8810
       4                        82                          0          31600          7945
       5                        82                          0          32540          7005

=== Per-Fold Results ===
|        |   accuracy |   precision |   recall |     f1 |
|--------|------------|-------------|----------|--------|
| Fold 1 |     0.8897 |      0.9010 |   0.9479 | 0.9239 |
| Fold 2 |     0.9926 |      0.9897 |   1.0000 | 0.9948 |
| Fold 3 |     0.9922 |      0.9888 |   1.0000 | 0.9944 |
| Fold 4 |     0.9922 |      0.9888 |   1.0000 | 0.9944 |
| Fold 5 |     0.9922 |      1.0000 |   0.9896 | 0.9948 |

================================================================================
üöÄ RUNNING ENSEMBLE EVALUATION FOR MAXIMUM ACCURACY
================================================================================
/workspace/BC-Attention-Fusion/main.py:248: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(f'output/best_model_fold_{fold}.pth', map_location=device)
üî• Running Multi-Fold Ensemble Evaluation
============================================================

üìä Evaluating Fold 1
TTA Prediction: 100%|--------| 8/8 [00:01<00:00,  5.33it/s]

üìä Evaluating Fold 2
TTA Prediction: 100%|--------| 8/8 [00:01<00:00,  5.40it/s]

üìä Evaluating Fold 3
TTA Prediction: 100%|--------| 8/8 [00:01<00:00,  4.99it/s]

üìä Evaluating Fold 4
TTA Prediction: 100%|--------| 8/8 [00:01<00:00,  5.54it/s]

üìä Evaluating Fold 5
TTA Prediction: 100%|--------| 8/8 [00:01<00:00,  5.48it/s]

üéØ Combining 5 fold predictions...
Ensemble Results:
  Accuracy: 1.0000
  Balanced Accuracy: 1.0000
  F1 Score: 1.0000

Classification Report:
              precision    recall  f1-score   support

      Benign       1.00      1.00      1.00        32
   Malignant       1.00      1.00      1.00        96

    accuracy                           1.00       128
   macro avg       1.00      1.00      1.00       128
weighted avg       1.00      1.00      1.00       128


üéØ Confidence-based results:

--- Confidence >= 0.7 ---
Confidence threshold 0.7: 119/128 samples retained
Ensemble Results:
  Accuracy: 1.0000
  Balanced Accuracy: 1.0000
  F1 Score: 1.0000

Classification Report:
              precision    recall  f1-score   support

      Benign       1.00      1.00      1.00        32
   Malignant       1.00      1.00      1.00        87

    accuracy                           1.00       119
   macro avg       1.00      1.00      1.00       119
weighted avg       1.00      1.00      1.00       119


--- Confidence >= 0.8 ---
Confidence threshold 0.8: 112/128 samples retained
Ensemble Results:
  Accuracy: 1.0000
  Balanced Accuracy: 1.0000
  F1 Score: 1.0000

Classification Report:
              precision    recall  f1-score   support

      Benign       1.00      1.00      1.00        32
   Malignant       1.00      1.00      1.00        80

    accuracy                           1.00       112
   macro avg       1.00      1.00      1.00       112
weighted avg       1.00      1.00      1.00       112


--- Confidence >= 0.9 ---
Confidence threshold 0.9: 78/128 samples retained
Ensemble Results:
  Accuracy: 1.0000
  Balanced Accuracy: 1.0000
  F1 Score: 1.0000

Classification Report:
              precision    recall  f1-score   support

      Benign       1.00      1.00      1.00        31
   Malignant       1.00      1.00      1.00        47

    accuracy                           1.00        78
   macro avg       1.00      1.00      1.00        78
weighted avg       1.00      1.00      1.00        78


--- Confidence >= 0.95 ---
Confidence threshold 0.95: 29/128 samples retained
Ensemble Results:
  Accuracy: 1.0000
  Balanced Accuracy: 1.0000
  F1 Score: 1.0000

Classification Report:
              precision    recall  f1-score   support

      Benign       1.00      1.00      1.00        19
   Malignant       1.00      1.00      1.00        10

    accuracy                           1.00        29
   macro avg       1.00      1.00      1.00        29
weighted avg       1.00      1.00      1.00        29


üéØ FINAL ENSEMBLE ACCURACY: 1.0000
üéØ TARGET ACHIEVED: ‚úÖ YES
================================================================================